{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEBtwbteriQg"
   },
   "source": [
    "# **Delivery Duration Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaT-CV5prndW"
   },
   "source": [
    "## Assignment\n",
    "When a consumer places an order on DoorDash, we show the expected time of delivery. It is very important for DoorDash to get this right, as it has a big impact on consumer experience. In this exercise, you will build a model to predict the estimated time taken for a delivery.\n",
    "\n",
    "Concretely, for a given delivery you must predict the total delivery duration seconds , i.e., the time taken from\n",
    "\n",
    "Start: the time consumer submits the order (created_at) to\n",
    "End: when the order will be delivered to the consumer (actual_delivery_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e2myeO5sArQ"
   },
   "source": [
    "## Data Description\n",
    "\n",
    "The attached file historical_data.csv contains a subset of deliveries received at DoorDash in early 2015 in a subset of the cities. Each row in this file corresponds to one unique delivery. We have added noise to the dataset to obfuscate certain business details. Each column corresponds to a feature as explained below. Note all money (dollar) values given in the data are in cents and all time duration values given are in seconds\n",
    "\n",
    "The target value to predict here is the total seconds value between created_at and actual_delivery_time.\n",
    "\n",
    " - Columns in historical_data.csv\n",
    "\n",
    "**Time features**\n",
    "\n",
    "- market_id: A city/region in which DoorDash operates, e.g., Los Angeles, given in the data as an id\n",
    "\n",
    "- created_at: Timestamp in UTC when the order was submitted by the consumer to DoorDash. (Note this timestamp is in UTC, but in case you need it, the actual timezone of the region was US/Pacific)\n",
    "actual_delivery_time: Timestamp in UTC when the order was delivered to the consumer\n",
    "\n",
    "\n",
    "**Store features**\n",
    "\n",
    "- store_id: an id representing the restaurant the order was submitted for\n",
    "- store_primary_category: cuisine category of the restaurant, e.g., italian, asian\n",
    "- order_protocol: a store can receive orders from DoorDash through many modes. This field represents an id denoting the protocol\n",
    "\n",
    "**Order features**\n",
    "\n",
    "- total_items: total number of items in the order\n",
    "- subtotal: total value of the order submitted (in cents)\n",
    "- num_distinct_items: number of distinct items included in the order\n",
    "- min_item_price: price of the item with the least cost in the order (in cents)\n",
    "- max_item_price: price of the item with the highest cost in the order (in cents)\n",
    "\n",
    "**Market features**\n",
    "\n",
    "DoorDash being a marketplace, we have information on the state of marketplace when the order is placed, that can be used to estimate delivery time. The following features are values at the time of created_at (order submission time):\n",
    "\n",
    "- total_onshift_dashers: Number of available dashers who are within 10 miles of the store at the time of order creation\n",
    "- total_busy_dashers: Subset of above total_onshift_dashers who are currently working on an order\n",
    "- total_outstanding_orders: Number of orders within 10 miles of this order that are currently being processed.\n",
    "\n",
    "**Predictions from other models**\n",
    "\n",
    "We have predictions from other models for various stages of delivery process that we can use:\n",
    "\n",
    "- estimated_order_place_duration: Estimated time for the restaurant to receive the order from DoorDash (in seconds)\n",
    "- estimated_store_to_consumer_driving_duration: Estimated travel time between store and consumer (in seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpO6ElTGswNy"
   },
   "source": [
    "**Practicalities**\n",
    "Build a model to predict the total delivery duration seconds (as defined above). Feel free to generate additional features from the given data to improve model performance. Explain:\n",
    "\n",
    "- model(s) used,\n",
    "- how you evaluated your model performance on the historical data,\n",
    "- any data processing you performed on the data,\n",
    "- feature engineering choices you made,\n",
    "- other information you would like to share your modeling approach.\n",
    "\n",
    "- We expect the project to take 3-5 hours in total, but feel free to spend as much time as you like on it. Feel free to use any open source packages for the task.\n",
    "\n",
    "\n",
    "#### To download the dataset <a href=\"https://drive.google.com/drive/folders/1H4wDwJhfElUd4OfkaoH_VIZhvwDuOMxf?usp=sharing\"> Click here </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   market_id           created_at actual_delivery_time  store_id  \\\n",
      "0        1.0  2015-02-06 22:24:17  2015-02-06 23:27:16      1845   \n",
      "1        2.0  2015-02-10 21:49:25  2015-02-10 22:56:29      5477   \n",
      "2        3.0  2015-01-22 20:39:28  2015-01-22 21:09:09      5477   \n",
      "3        3.0  2015-02-03 21:21:45  2015-02-03 22:13:00      5477   \n",
      "4        3.0  2015-02-15 02:40:36  2015-02-15 03:20:26      5477   \n",
      "\n",
      "  store_primary_category  order_protocol  total_items  subtotal  \\\n",
      "0               american             1.0            4      3441   \n",
      "1                mexican             2.0            1      1900   \n",
      "2                    NaN             1.0            1      1900   \n",
      "3                    NaN             1.0            6      6900   \n",
      "4                    NaN             1.0            3      3900   \n",
      "\n",
      "   num_distinct_items  min_item_price  max_item_price  total_onshift_dashers  \\\n",
      "0                   4             557            1239                   33.0   \n",
      "1                   1            1400            1400                    1.0   \n",
      "2                   1            1900            1900                    1.0   \n",
      "3                   5             600            1800                    1.0   \n",
      "4                   3            1100            1600                    6.0   \n",
      "\n",
      "   total_busy_dashers  total_outstanding_orders  \\\n",
      "0                14.0                      21.0   \n",
      "1                 2.0                       2.0   \n",
      "2                 0.0                       0.0   \n",
      "3                 1.0                       2.0   \n",
      "4                 6.0                       9.0   \n",
      "\n",
      "   estimated_order_place_duration  \\\n",
      "0                             446   \n",
      "1                             446   \n",
      "2                             446   \n",
      "3                             446   \n",
      "4                             446   \n",
      "\n",
      "   estimated_store_to_consumer_driving_duration  \n",
      "0                                         861.0  \n",
      "1                                         690.0  \n",
      "2                                         690.0  \n",
      "3                                         289.0  \n",
      "4                                         650.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\manoj\\\\Downloads\\\\historical_data.csv\")\n",
    "# Check the loaded DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 197428 entries, 0 to 197427\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                        Non-Null Count   Dtype  \n",
      "---  ------                                        --------------   -----  \n",
      " 0   market_id                                     196441 non-null  float64\n",
      " 1   created_at                                    197428 non-null  object \n",
      " 2   actual_delivery_time                          197421 non-null  object \n",
      " 3   store_id                                      197428 non-null  int64  \n",
      " 4   store_primary_category                        192668 non-null  object \n",
      " 5   order_protocol                                196433 non-null  float64\n",
      " 6   total_items                                   197428 non-null  int64  \n",
      " 7   subtotal                                      197428 non-null  int64  \n",
      " 8   num_distinct_items                            197428 non-null  int64  \n",
      " 9   min_item_price                                197428 non-null  int64  \n",
      " 10  max_item_price                                197428 non-null  int64  \n",
      " 11  total_onshift_dashers                         181166 non-null  float64\n",
      " 12  total_busy_dashers                            181166 non-null  float64\n",
      " 13  total_outstanding_orders                      181166 non-null  float64\n",
      " 14  estimated_order_place_duration                197428 non-null  int64  \n",
      " 15  estimated_store_to_consumer_driving_duration  196902 non-null  float64\n",
      "dtypes: float64(6), int64(7), object(3)\n",
      "memory usage: 24.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check the loaded DataFrame\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data['actual_delivery_time'] = pd.to_datetime(data['actual_delivery_time'])\n",
    "\n",
    "# Calculate target variable: delivery duration\n",
    "data['delivery_duration'] = (data['actual_delivery_time'] - data['created_at']).dt.total_seconds()\n",
    "\n",
    "# Extract day of the week and hour of the day from created_at timestamp\n",
    "data['day_of_week'] = data['created_at'].dt.dayofweek\n",
    "data['hour_of_day'] = data['created_at'].dt.hour\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (fill with median for numeric, mode for categorical)\n",
    "data['market_id'].fillna(data['market_id'].mode()[0], inplace=True)\n",
    "data['store_primary_category'].fillna(data['store_primary_category'].mode()[0], inplace=True)\n",
    "data['order_protocol'].fillna(data['order_protocol'].mode()[0], inplace=True)\n",
    "data['total_onshift_dashers'].fillna(data['total_onshift_dashers'].median(), inplace=True)\n",
    "data['total_busy_dashers'].fillna(data['total_busy_dashers'].median(), inplace=True)\n",
    "data['total_outstanding_orders'].fillna(data['total_outstanding_orders'].median(), inplace=True)\n",
    "data['estimated_store_to_consumer_driving_duration'].fillna(data['estimated_store_to_consumer_driving_duration'].median(), inplace=True)\n",
    "\n",
    "# Drop rows where the target variable is NaN\n",
    "data.dropna(subset=['delivery_duration'], inplace=True)\n",
    "\n",
    "# Define features and target\n",
    "features = ['market_id', 'store_primary_category', 'order_protocol', 'total_items',\n",
    "            'subtotal', 'num_distinct_items', 'min_item_price', 'max_item_price',\n",
    "            'total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "            'estimated_order_place_duration', 'estimated_store_to_consumer_driving_duration',\n",
    "            'day_of_week', 'hour_of_day']\n",
    "target = 'delivery_duration'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "categorical_features = ['market_id', 'store_primary_category', 'order_protocol', 'day_of_week', 'hour_of_day']\n",
    "numerical_features = list(set(features) - set(categorical_features))\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 748.3181648388801\n",
      "Root Mean Squared Error: 2161.0494226593582\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', model)])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess and train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters: {'model__max_depth': 20, 'model__min_samples_leaf': 3, 'model__min_samples_split': 7, 'model__n_estimators': 130}\n",
      "Mean Absolute Error: 748.1048206011676\n",
      "Root Mean Squared Error: 1419.8857283346824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', model)])\n",
    "\n",
    "# Define the parameter grid for Randomized Search\n",
    "param_dist = {\n",
    "    'model__n_estimators': randint(50, 200),\n",
    "    'model__max_depth': [None, 10, 20, 30],\n",
    "    'model__min_samples_split': randint(2, 10),\n",
    "    'model__min_samples_leaf': randint(1, 4)\n",
    "}\n",
    "\n",
    "# Set up Randomized Search\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=20, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f'Best Model Parameters: {random_search.best_params_}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNCQcexnSsg4I61ruLwD+Vq",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
